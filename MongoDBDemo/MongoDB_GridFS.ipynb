{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MongoDB GridFS demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by Dr. Rikard Sandström, rsandstroem@kpmg.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have not done so already, I recommend that you first look at \"MongoDB_demo.ipynb\" in this repository. It explains the basics in MongoDB and introduces pymongo.\n",
    "\n",
    "This demonstration shows how to use GridFS for storing large files in MongoDB. MongoDB has a document size limit of a few MB. GridFS circumvents this by splitting the file in smaller chunks. I find it convenient for storing binary data such as images and video. For more information please see https://docs.mongodb.org/manual/core/gridfs/\n",
    "\n",
    "The demonstration stores a scanned pdf in GridFS, then extracts text from the pdf and adds that as another \"column\" of the same collection. This allows retrieval of pdf's whos content match user defined search terms. This use case was brought to life by my frustration over searching through piles of papers when filling out my tax returns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a MongoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import things we will need. Use pymongo to connect to the \"test\" database on port 27017 of the local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import bson\n",
    "import gridfs\n",
    "import textract\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a GridFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start from a clean slate, begin by dropping the collections GridFS might have created earlier. GridFS creates a \"files\" collection, containing meta data, and the \"chunks\" collection, containing small chunks of the large files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#db.drop_collection('fs.files')\n",
    "#db.drop_collection('fs.chunks')\n",
    "fs = gridfs.GridFS(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's insert an object and see if we can retrieve it. The object in this case is just a string containing \"Hello World\". Add some additional free text description called \"text\" and a tag field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put returned:\t5702b882b14376090e8dbec2\n",
      "database contains:\tHello World\n"
     ]
    }
   ],
   "source": [
    "a = fs.put(\"Hello World\", text='I am a tiny document', tags=['foo', 'bar'], username='skywalker')\n",
    "print 'put returned:\\t', a\n",
    "print 'database contains:\\t', fs.get(a).read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract text from a scanned PDF file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try something more complex. \"scansmpl.pdf\" is a free sample of a scanned pdf file containing text in image format. For pdf files already containing text in text format we can just grab the text with pdftotext. If this does not work we need to run and OCR to optically reconstruct characters from the image, which is much slower. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# old method\n",
    "\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.converter import XMLConverter, HTMLConverter, TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from cStringIO import StringIO\n",
    "\n",
    "def pdfparser(data):\n",
    "\n",
    "    fp = file(data, 'rb')\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    # Create a PDF interpreter object.\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    # Process each page contained in the document.\n",
    "\n",
    "    for page in PDFPage.get_pages(fp):\n",
    "        interpreter.process_page(page)\n",
    "        data =  retstr.getvalue()\n",
    "\n",
    "    return data\n",
    "    \n",
    "filename = 'scansmpl.pdf'\n",
    "tags = ['default']\n",
    "text = pdfparser(filename)\n",
    "if len(text)<2: # No text found, so we need to do an OCR \n",
    "    os.system('ocrmypdf ' + filename + ' ocr.pdf')\n",
    "    text = pdfparser('ocr.pdf')\n",
    "print 'Text consists of', len(text), 'words'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text consists of 1164 words\n",
      "\n",
      "No.\n",
      "\n",
      "THE SLEREXE COMPANY LIMITED\n",
      "\n",
      "SAPORS LANE - BOOLE - DORSET - BHZS HER\n",
      "I'ELEPHUNI not: (9513) 51617 - ďŹux 123456\n",
      "\n",
      "Our Ref. 350/PJC/EAC 18th January, 1972.\n",
      "\n",
      "Dr. KN. Cundall,\n",
      "Mining Surveys Ltd.,\n",
      "Holroyd Road,\n",
      "Reading,\n",
      "\n",
      "Berks.\n",
      "\n",
      "Deer Pete,\n",
      "\n",
      "Permit me to introduce you to the facility of facsimile\n",
      "transmission.\n",
      "\n",
      "In facsimile a photocell is caused to perform a raster scan over\n",
      "the subject copy. The variations of print density on the document\n",
      "cause the photocell to generate an analogous electrical video signal.\n",
      "This signal is used to modulate a carrier, which is transmitted to a\n",
      "remote destination over a radio or cable communications link.\n",
      "\n",
      "At the remote terminal, demodulation reconstructs the video\n",
      "signal, which is used to modulate the density of print produced by a\n",
      "printing device. This device is scanning in a raster scan synchronised\n",
      "with that at the transmitting terminal. As a result, a facsimile\n",
      "copy of the subject document is produced.\n",
      "\n",
      "Probably you have uses for this facility in your organisation.\n",
      "\n",
      "Yours sincerely,\n",
      "\n",
      "W.\n",
      "P.J. CROSS\n",
      "Group Leader - Facsimile Research\n",
      "\n",
      "Registered in Bun Nu. noes\n",
      "nqimnd omâ: so vmr. Lune, [Her-l. mun.\n",
      "\n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = 'scansmpl.pdf'\n",
    "tags = ['default']\n",
    "# First try to extract text fields if present\n",
    "text = textract.process(filename, method='pdftotext')\n",
    "if len(text)<5: # No text found, it is probably an image scan, so we need to do an OCR \n",
    "    text = textract.process(filename, method='tesseract')\n",
    "print 'Text consists of', len(text), 'words\\n'\n",
    "print text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert the document to the data base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First convert the pdf to binary format. Then insert the binary version of the original file into mongo, together with the text extraction we did in the previous step and the file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectId('5702b8e5b14376090e8dbec4')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = bson.Binary(open(filename).read())\n",
    "fs.put(filename=filename, data=data, text=text, tags=tags, username='dvader')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect data base contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use command list() to get an array of files that were inserted. There should only be one file at this point, but if you inserted it multiple times it would not repeat in the array, so let's count replicas just to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Decision trees', u'ForIngrid.pdf', u'Naive_Bayes.pdf', u'Scanned', u'Scanned.pdf', u'Test.pdf', u'_8ec15376d6dab5439b7428eb0d8f0b70_Na_ve-Bayes-Assignment.pdf', u'scansmpl.pdf']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print fs.list()\n",
    "print fs.find({\"filename\" : \"scansmpl.pdf\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the meta data was stored in fs.files? You can see what each document contains using this collection, like shown below. The \"_id\" links to the inserted object in fs.chunks. Very convenient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'_id': ObjectId('56fe679cb143762514358152'),\n",
       "  u'chunkSize': 261120,\n",
       "  u'length': 11,\n",
       "  u'md5': u'b10a8db164e0754105b7a99be72e3fe5',\n",
       "  u'tags': [u'foo', u'bar'],\n",
       "  u'text': u'I am a tiny document',\n",
       "  u'uploadDate': datetime.datetime(2016, 4, 1, 12, 20, 44, 60000),\n",
       "  u'username': u'skywalker'},\n",
       " {u'_id': ObjectId('56fe67a3b143762514358154'),\n",
       "  u'chunkSize': 261120,\n",
       "  u'filename': u'scansmpl.pdf',\n",
       "  u'length': 21530,\n",
       "  u'md5': u'8d2fc6d280b1385302910fd5162eaad2',\n",
       "  u'tags': [u'default'],\n",
       "  u'text': u'THE SLEREXE COMPANY LIMITED\\nSAPORS LANE\\nTELEPHONE\\n\\nOur Ref.\\n\\n350/PJC/EAC\\n\\nDr.\\n\\nCundall,\\n\\nP.N.\\n\\n.\\n\\nBOOLE\\n\\nBoots\\n\\n-\\n\\nDORSET\\n\\n(94513) 51617\\n\\n-\\n\\n.\\n\\nBHZS SER\\n\\n123456\\n\\nnuax\\n\\n18th\\n\\nJanuary, 1972.\\n\\nMining Surveys Ltd.,\\nHolroyd Road,\\n\\nReading,\\nBerks.\\n\\nDear\\n\\nPete,\\n\\nPermit me\\ntransmission.\\n\\nintroduce you\\n\\nto\\n\\nto\\n\\nfacility\\n\\nthe\\n\\nof\\n\\nfacsimile\\n\\nphotocell is caused to perform a raster scan over\\nvariations of print density on the document\\nsubject copy.\\ncause the photocell to generate an analogous electrical video signal.\\nThis signal is used to modulate a carrier, which is transmitted to a\\nIn\\n\\nfacsimile\\n\\na\\n\\nThe\\n\\nthe\\n\\nremote\\n\\nAt\\n\\ndestination\\nthe\\n\\nremote\\n\\nover\\n\\na\\n\\nradio\\n\\nterminal,\\n\\nor\\n\\ncommunications link.\\n\\ncable\\n\\ndemodulation\\n\\nreconstructs\\n\\nthe video\\n\\ndensity of print produced by a\\nThis device is scanning in a raster scan synchronised\\nAs a result, a facsimile\\nwith that at the transmitting terminal.\\nis\\nof\\nthe\\ndocument\\ncopy\\nsubject\\nproduced.\\n\\nsignal, which is\\nprinting device.\\n\\nProbably\\n\\nused to modulate\\n\\nyou have\\n\\nuses\\n\\nthe\\n\\nfor this\\n\\nfacility\\nYours\\n\\nin your\\n\\norganisation.\\n\\nsincerely,\\n\\nW.\\nP.J.\\n\\nCROSS\\n\\nGroup Leader\\n\\nNo.\\n\\nRexlnered\\nRegistered Office:\\n\\nin\\n\\n-\\n\\nFacsimile Research\\n\\nEngland:\\n\\nNo. 2038\\n\\n80 Vicar-I\\n\\nLune, Illord. Enos.\\n\\n\\x0c',\n",
       "  u'uploadDate': datetime.datetime(2016, 4, 1, 12, 20, 51, 911000),\n",
       "  u'username': u'dvader'},\n",
       " {u'_id': ObjectId('56fe6f30b1437629b41701de'),\n",
       "  u'chunkSize': 261120,\n",
       "  u'filename': u'_8ec15376d6dab5439b7428eb0d8f0b70_Na_ve-Bayes-Assignment.pdf',\n",
       "  u'length': 221246,\n",
       "  u'md5': u'61efb9c5209fe122279f786f682c6e7d',\n",
       "  u'tags': [u'bla'],\n",
       "  u'text': u'Na\\xefve Bayes Assignment\\n\\nCreate a KNIME workflow that utilizes the Naive Bayes method to train a model on the Adult training\\ndata set. This data set can be found at the UCI machine learning repository.\\nhttp://archive.ics.uci.edu/ml/datasets/Adult\\nThis data set was developed by Barry Becker by extracting from the 1994 Census database.\\nPrediction task is to determine whether a person makes over 50K a year.\\nUse the file reader node to read in the training data file from:\\nhttp://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\\nThe Naive Bayes method is available in the Node repository panel under \\u201cMining\\u201d-> \\u201cBayes\\u201d category.\\nThere are two different nodes: \\u201cNa\\xefve Bayes Learner\\u201d and \\u201cNa\\xefve Bayes Predictor\\u201d. Na\\xefve Bayes learner\\nnode creates a Bayesian model from the input training data. The Na\\xefve Bayes Predictor node applies an\\nexisting Bayesian modes to the input data table. Additionally, the scorer node should be added at the\\nend of the workflow in order to measure classifiers\\u2019 performance.\\n\\n\\x0cTask #1.\\nBy utilizing the simple Na\\xefve Bayes learner, predictor and scorer nodes \\u2013 how well was the Model able to\\nlearn to predict income (<=50K or >50K). Hint: take a look at the confusion matrix within the scorer\\nnode. Since in this exercise we are using the entire training data set to evaluate the model \\u2013 we are\\nlooking at what is called the re-substitution error.\\nTask #2.\\nIn order to properly evaluate the trained model \\u2013 lets\\u2019 split the data into training and testing by utilizing\\nthe \\u201cPartitioning\\u201d node. Split into 66%-33% subset for training and testing. What is the evaluation of the\\nmodel performance estimated now? Looking at the accuracy statistics \\u2013 which class has a better\\nPrecision and F-Measure?\\nTask #3\\nUpload the Iris data set. Train the Na\\xefve Bayes model on the partitioned data set. Which one of the 3\\nIris class has the highest number of true positives?\\n\\n\\x0c',\n",
       "  u'uploadDate': datetime.datetime(2016, 4, 1, 12, 53, 4, 841000),\n",
       "  u'username': u'Rikard'},\n",
       " {u'_id': ObjectId('5702b882b14376090e8dbec2'),\n",
       "  u'chunkSize': 261120,\n",
       "  u'length': 11,\n",
       "  u'md5': u'b10a8db164e0754105b7a99be72e3fe5',\n",
       "  u'tags': [u'foo', u'bar'],\n",
       "  u'text': u'I am a tiny document',\n",
       "  u'uploadDate': datetime.datetime(2016, 4, 4, 18, 54, 58, 665000),\n",
       "  u'username': u'skywalker'},\n",
       " {u'_id': ObjectId('56fe6f5bb1437629b41701e0'),\n",
       "  u'chunkSize': 261120,\n",
       "  u'filename': u'scansmpl.pdf',\n",
       "  u'length': 21530,\n",
       "  u'md5': u'8d2fc6d280b1385302910fd5162eaad2',\n",
       "  u'tags': [u'test'],\n",
       "  u'text': u'THE SLEREXE COMPANY LIMITED\\nSAPORS LANE\\nTELEPHONE\\n\\nOur Ref.\\n\\n350/PJC/EAC\\n\\nDr.\\n\\nCundall,\\n\\nP.N.\\n\\n.\\n\\nBOOLE\\n\\nBoots\\n\\n-\\n\\nDORSET\\n\\n(94513) 51617\\n\\n-\\n\\n.\\n\\nBHZS SER\\n\\n123456\\n\\nnuax\\n\\n18th\\n\\nJanuary, 1972.\\n\\nMining Surveys Ltd.,\\nHolroyd Road,\\n\\nReading,\\nBerks.\\n\\nDear\\n\\nPete,\\n\\nPermit me\\ntransmission.\\n\\nintroduce you\\n\\nto\\n\\nto\\n\\nfacility\\n\\nthe\\n\\nof\\n\\nfacsimile\\n\\nphotocell is caused to perform a raster scan over\\nvariations of print density on the document\\nsubject copy.\\ncause the photocell to generate an analogous electrical video signal.\\nThis signal is used to modulate a carrier, which is transmitted to a\\nIn\\n\\nfacsimile\\n\\na\\n\\nThe\\n\\nthe\\n\\nremote\\n\\nAt\\n\\ndestination\\nthe\\n\\nremote\\n\\nover\\n\\na\\n\\nradio\\n\\nterminal,\\n\\nor\\n\\ncommunications link.\\n\\ncable\\n\\ndemodulation\\n\\nreconstructs\\n\\nthe video\\n\\ndensity of print produced by a\\nThis device is scanning in a raster scan synchronised\\nAs a result, a facsimile\\nwith that at the transmitting terminal.\\nis\\nof\\nthe\\ndocument\\ncopy\\nsubject\\nproduced.\\n\\nsignal, which is\\nprinting device.\\n\\nProbably\\n\\nused to modulate\\n\\nyou have\\n\\nuses\\n\\nthe\\n\\nfor this\\n\\nfacility\\nYours\\n\\nin your\\n\\norganisation.\\n\\nsincerely,\\n\\nW.\\nP.J.\\n\\nCROSS\\n\\nGroup Leader\\n\\nNo.\\n\\nRexlnered\\nRegistered Office:\\n\\nin\\n\\n-\\n\\nFacsimile Research\\n\\nEngland:\\n\\nNo. 2038\\n\\n80 Vicar-I\\n\\nLune, Illord. Enos.\\n\\n\\x0c',\n",
       "  u'uploadDate': datetime.datetime(2016, 4, 1, 12, 53, 47, 650000),\n",
       "  u'username': u'Rikard'},\n",
       " {u'_id': ObjectId('56fe707db143762b76a1864b'),\n",
       "  u'chunkSize': 261120,\n",
       "  u'filename': u'Decision trees',\n",
       "  u'length': 94296,\n",
       "  u'md5': u'5cf70d9d84264845187a66d68c148183',\n",
       "  u'tags': [u'Machinelearning'],\n",
       "  u'text': u'Decision Tree Assignment\\nCreate a KNIME workflow that utilizes the Decision Tree learning method to train a model on the Iris\\ntraining data set. This data set can be found at the UCI machine learning repository.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe Decision Tree method is available in the Node repository panel under \\u201cMining\\u201d-> \\u201cDecision Tree\\u201d\\ncategory. There are two different nodes: \\u201cDecision Tree Learner\\u201d and \\u201cDecision Tree Predictor\\u201d.\\nDecision Tree learner node creates a Decision Tree model from the input training data. The Decision\\nTree Predictor node applies an existing Decision Tree modes to the input data table. Additionally, the\\nscorer node should be added at the end of the workflow in order to measure classifiers\\u2019 performance.\\nhttps://www.knime.org/introduction/examples\\nAn example of the workflow should look like the workflow below:\\n\\nhttps://www.knime.org/introduction/examples\\n\\nTask #1.\\nBy utilizing the Decision Tree learner, predictor and scorer nodes \\u2013 how well was the Model able to learn\\nto predict Iris flowers. Hint: take a look at the confusion matrix within the scorer node. How many Irissetosas has the Decision Tree misclassified?\\n\\n\\x0cTask #2.\\nLooking at the accuracy statistics of the scoring node on the Decision Tree model trained on the Iris data\\nset\\u2013 which class had the highest Recall and Precision?\\nTask #3\\nCreate a KNIME workflow that utilizes the Decision Tree learning method to train a model on the Adult\\ntraining data set. This data set can be found at the UCI machine learning repository.\\nhttp://archive.ics.uci.edu/ml/datasets/Adult\\nThis data set was developed by Barry Becker by extracting from the 1994 Census database.\\nPrediction task is to determine whether a person makes over 50K a year.\\nUse the file reader node to read in the training data file from:\\nhttp://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\\nLooking at the accuracy statistics of the scoring node \\u2013 which class had the highest Recall and Precision?\\nTask #4\\nChange the Decision Tree learner node parameters (for the Adult training data set) from the default Gini\\nindex to Gain Ratio. By changing this parameter \\u2013 did the resulting tree able to obtain a higher or lower\\nerror than the default Gini index?\\nTask #5\\nChange the Decision Tree learner node Pruning Method Parameter to MDL pruning. Is the resulting tree\\nable to obtain a higher or lower overall prediction error as compared to no pruning alternative?\\n\\n\\x0c',\n",
       "  u'uploadDate': datetime.datetime(2016, 4, 1, 12, 58, 37, 126000),\n",
       "  u'username': u'Rikard'},\n",
       " {u'_id': ObjectId('56fe70ccb143762b76a1864d'),\n",
       "  u'chunkSize': 261120,\n",
       "  u'filename': u'Scanned',\n",
       "  u'length': 21530,\n",
       "  u'md5': u'8d2fc6d280b1385302910fd5162eaad2',\n",
       "  u'tags': [u'OCR'],\n",
       "  u'text': u'THE SLEREXE COMPANY LIMITED\\nSAPORS LANE\\nTELEPHONE\\n\\nOur Ref.\\n\\n350/PJC/EAC\\n\\nDr.\\n\\nCundall,\\n\\nP.N.\\n\\n.\\n\\nBOOLE\\n\\nBoots\\n\\n-\\n\\nDORSET\\n\\n(94513) 51617\\n\\n-\\n\\n.\\n\\nBHZS SER\\n\\n123456\\n\\nnuax\\n\\n18th\\n\\nJanuary, 1972.\\n\\nMining Surveys Ltd.,\\nHolroyd Road,\\n\\nReading,\\nBerks.\\n\\nDear\\n\\nPete,\\n\\nPermit me\\ntransmission.\\n\\nintroduce you\\n\\nto\\n\\nto\\n\\nfacility\\n\\nthe\\n\\nof\\n\\nfacsimile\\n\\nphotocell is caused to perform a raster scan over\\nvariations of print density on the document\\nsubject copy.\\ncause the photocell to generate an analogous electrical video signal.\\nThis signal is used to modulate a carrier, which is transmitted to a\\nIn\\n\\nfacsimile\\n\\na\\n\\nThe\\n\\nthe\\n\\nremote\\n\\nAt\\n\\ndestination\\nthe\\n\\nremote\\n\\nover\\n\\na\\n\\nradio\\n\\nterminal,\\n\\nor\\n\\ncommunications link.\\n\\ncable\\n\\ndemodulation\\n\\nreconstructs\\n\\nthe video\\n\\ndensity of print produced by a\\nThis device is scanning in a raster scan synchronised\\nAs a result, a facsimile\\nwith that at the transmitting terminal.\\nis\\nof\\nthe\\ndocument\\ncopy\\nsubject\\nproduced.\\n\\nsignal, which is\\nprinting device.\\n\\nProbably\\n\\nused to modulate\\n\\nyou have\\n\\nuses\\n\\nthe\\n\\nfor this\\n\\nfacility\\nYours\\n\\nin your\\n\\norganisation.\\n\\nsincerely,\\n\\nW.\\nP.J.\\n\\nCROSS\\n\\nGroup Leader\\n\\nNo.\\n\\nRexlnered\\nRegistered Office:\\n\\nin\\n\\n-\\n\\nFacsimile Research\\n\\nEngland:\\n\\nNo. 2038\\n\\n80 Vicar-I\\n\\nLune, Illord. Enos.\\n\\n\\x0c',\n",
       "  u'uploadDate': datetime.datetime(2016, 4, 1, 12, 59, 56, 224000),\n",
       "  u'username': u'Rikard'},\n",
       " {u'_id': ObjectId('56fe71a9b143762b76a1864f'),\n",
       "  u'chunkSize': 261120,\n",
       "  u'filename': u'Scanned.pdf',\n",
       "  u'length': 21530,\n",
       "  u'md5': u'8d2fc6d280b1385302910fd5162eaad2',\n",
       "  u'tags': [u'OCR'],\n",
       "  u'text': u'THE SLEREXE COMPANY LIMITED\\nSAPORS LANE\\nTELEPHONE\\n\\nOur Ref.\\n\\n350/PJC/EAC\\n\\nDr.\\n\\nCundall,\\n\\nP.N.\\n\\n.\\n\\nBOOLE\\n\\nBoots\\n\\n-\\n\\nDORSET\\n\\n(94513) 51617\\n\\n-\\n\\n.\\n\\nBHZS SER\\n\\n123456\\n\\nnuax\\n\\n18th\\n\\nJanuary, 1972.\\n\\nMining Surveys Ltd.,\\nHolroyd Road,\\n\\nReading,\\nBerks.\\n\\nDear\\n\\nPete,\\n\\nPermit me\\ntransmission.\\n\\nintroduce you\\n\\nto\\n\\nto\\n\\nfacility\\n\\nthe\\n\\nof\\n\\nfacsimile\\n\\nphotocell is caused to perform a raster scan over\\nvariations of print density on the document\\nsubject copy.\\ncause the photocell to generate an analogous electrical video signal.\\nThis signal is used to modulate a carrier, which is transmitted to a\\nIn\\n\\nfacsimile\\n\\na\\n\\nThe\\n\\nthe\\n\\nremote\\n\\nAt\\n\\ndestination\\nthe\\n\\nremote\\n\\nover\\n\\na\\n\\nradio\\n\\nterminal,\\n\\nor\\n\\ncommunications link.\\n\\ncable\\n\\ndemodulation\\n\\nreconstructs\\n\\nthe video\\n\\ndensity of print produced by a\\nThis device is scanning in a raster scan synchronised\\nAs a result, a facsimile\\nwith that at the transmitting terminal.\\nis\\nof\\nthe\\ndocument\\ncopy\\nsubject\\nproduced.\\n\\nsignal, which is\\nprinting device.\\n\\nProbably\\n\\nused to modulate\\n\\nyou have\\n\\nuses\\n\\nthe\\n\\nfor this\\n\\nfacility\\nYours\\n\\nin your\\n\\norganisation.\\n\\nsincerely,\\n\\nW.\\nP.J.\\n\\nCROSS\\n\\nGroup Leader\\n\\nNo.\\n\\nRexlnered\\nRegistered Office:\\n\\nin\\n\\n-\\n\\nFacsimile Research\\n\\nEngland:\\n\\nNo. 2038\\n\\n80 Vicar-I\\n\\nLune, Illord. Enos.\\n\\n\\x0c',\n",
       "  u'uploadDate': datetime.datetime(2016, 4, 1, 13, 3, 37, 975000),\n",
       "  u'username': u'Rikard'},\n",
       " {u'_id': ObjectId('56fe7215b143762b76a18651'),\n",
       "  u'chunkSize': 261120,\n",
       "  u'filename': u'Naive_Bayes.pdf',\n",
       "  u'length': 221246,\n",
       "  u'md5': u'61efb9c5209fe122279f786f682c6e7d',\n",
       "  u'tags': [u'Machinelearning'],\n",
       "  u'text': u'Na\\xefve Bayes Assignment\\n\\nCreate a KNIME workflow that utilizes the Naive Bayes method to train a model on the Adult training\\ndata set. This data set can be found at the UCI machine learning repository.\\nhttp://archive.ics.uci.edu/ml/datasets/Adult\\nThis data set was developed by Barry Becker by extracting from the 1994 Census database.\\nPrediction task is to determine whether a person makes over 50K a year.\\nUse the file reader node to read in the training data file from:\\nhttp://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\\nThe Naive Bayes method is available in the Node repository panel under \\u201cMining\\u201d-> \\u201cBayes\\u201d category.\\nThere are two different nodes: \\u201cNa\\xefve Bayes Learner\\u201d and \\u201cNa\\xefve Bayes Predictor\\u201d. Na\\xefve Bayes learner\\nnode creates a Bayesian model from the input training data. The Na\\xefve Bayes Predictor node applies an\\nexisting Bayesian modes to the input data table. Additionally, the scorer node should be added at the\\nend of the workflow in order to measure classifiers\\u2019 performance.\\n\\n\\x0cTask #1.\\nBy utilizing the simple Na\\xefve Bayes learner, predictor and scorer nodes \\u2013 how well was the Model able to\\nlearn to predict income (<=50K or >50K). Hint: take a look at the confusion matrix within the scorer\\nnode. Since in this exercise we are using the entire training data set to evaluate the model \\u2013 we are\\nlooking at what is called the re-substitution error.\\nTask #2.\\nIn order to properly evaluate the trained model \\u2013 lets\\u2019 split the data into training and testing by utilizing\\nthe \\u201cPartitioning\\u201d node. Split into 66%-33% subset for training and testing. What is the evaluation of the\\nmodel performance estimated now? Looking at the accuracy statistics \\u2013 which class has a better\\nPrecision and F-Measure?\\nTask #3\\nUpload the Iris data set. Train the Na\\xefve Bayes model on the partitioned data set. Which one of the 3\\nIris class has the highest number of true positives?\\n\\n\\x0c',\n",
       "  u'uploadDate': datetime.datetime(2016, 4, 1, 13, 5, 25, 203000),\n",
       "  u'username': u'Rikard'},\n",
       " {u'_id': ObjectId('56fe8275b143760b3a0d366c'),\n",
       "  u'chunkSize': 261120,\n",
       "  u'filename': u'Test.pdf',\n",
       "  u'length': 94296,\n",
       "  u'md5': u'5cf70d9d84264845187a66d68c148183',\n",
       "  u'tags': [u'test'],\n",
       "  u'text': u'Decision Tree Assignment\\nCreate a KNIME workflow that utilizes the Decision Tree learning method to train a model on the Iris\\ntraining data set. This data set can be found at the UCI machine learning repository.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe Decision Tree method is available in the Node repository panel under \\u201cMining\\u201d-> \\u201cDecision Tree\\u201d\\ncategory. There are two different nodes: \\u201cDecision Tree Learner\\u201d and \\u201cDecision Tree Predictor\\u201d.\\nDecision Tree learner node creates a Decision Tree model from the input training data. The Decision\\nTree Predictor node applies an existing Decision Tree modes to the input data table. Additionally, the\\nscorer node should be added at the end of the workflow in order to measure classifiers\\u2019 performance.\\nhttps://www.knime.org/introduction/examples\\nAn example of the workflow should look like the workflow below:\\n\\nhttps://www.knime.org/introduction/examples\\n\\nTask #1.\\nBy utilizing the Decision Tree learner, predictor and scorer nodes \\u2013 how well was the Model able to learn\\nto predict Iris flowers. Hint: take a look at the confusion matrix within the scorer node. How many Irissetosas has the Decision Tree misclassified?\\n\\n\\x0cTask #2.\\nLooking at the accuracy statistics of the scoring node on the Decision Tree model trained on the Iris data\\nset\\u2013 which class had the highest Recall and Precision?\\nTask #3\\nCreate a KNIME workflow that utilizes the Decision Tree learning method to train a model on the Adult\\ntraining data set. This data set can be found at the UCI machine learning repository.\\nhttp://archive.ics.uci.edu/ml/datasets/Adult\\nThis data set was developed by Barry Becker by extracting from the 1994 Census database.\\nPrediction task is to determine whether a person makes over 50K a year.\\nUse the file reader node to read in the training data file from:\\nhttp://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\\nLooking at the accuracy statistics of the scoring node \\u2013 which class had the highest Recall and Precision?\\nTask #4\\nChange the Decision Tree learner node parameters (for the Adult training data set) from the default Gini\\nindex to Gain Ratio. By changing this parameter \\u2013 did the resulting tree able to obtain a higher or lower\\nerror than the default Gini index?\\nTask #5\\nChange the Decision Tree learner node Pruning Method Parameter to MDL pruning. Is the resulting tree\\nable to obtain a higher or lower overall prediction error as compared to no pruning alternative?\\n\\n\\x0c',\n",
       "  u'uploadDate': datetime.datetime(2016, 4, 1, 14, 15, 17, 348000),\n",
       "  u'username': u'Rikard'},\n",
       " {u'_id': ObjectId('56fed8e8b143760d02a10891'),\n",
       "  u'chunkSize': 261120,\n",
       "  u'comments': [{u'author': u'Rikard', u'body': u'ggg'}],\n",
       "  u'filename': u'ForIngrid.pdf',\n",
       "  u'length': 378227,\n",
       "  u'md5': u'95542b4e72d0f45ee789d2ae1406cbe7',\n",
       "  u'tags': [u'Ingrid', u'Tax'],\n",
       "  u'text': u'Statistical Modeling Approach\\nTwo assumptions\\nAttributes are\\n\\u2022 equally important\\n\\u2022 statistically independent\\n\\n\\x0cStatistical Modeling Approach\\nKnowledge about the value of a\\nparticular attribute doesn\\u2019t tell us\\nanything about the value of another\\nattribute (if the class is known)\\n\\n\\x0cStatistical Modeling Approach\\nAssumptions that are almost never correct\\nScheme works well in practice!\\n\\n\\x0cAttributes:\\n\\nWeather Data Set\\n\\nClass\\nAttribute\\n\\nDay\\n\\nOutlook\\n\\nTemp\\n\\nHumidity\\n\\nWind\\n\\nPlayTennis\\n\\nD1\\nD2\\nD3\\nD4\\nD5\\nD6\\nD7\\nD8\\nD9\\nD10\\nD11\\nD12\\nD13\\nD14\\n\\nSunny\\nSunny\\nOvercast\\nRain\\nRain\\nRain\\nOvercast\\nSunny\\nSunny\\nRain\\nSunny\\nOvercast\\nOvercast\\nRain\\n\\nHot\\nHot\\nHot\\nMild\\nCool\\nCool\\nCool\\nMild\\nCool\\nMild\\nMild\\nMild\\nHot\\nMild\\n\\nHigh\\nHigh\\nHigh\\nHigh\\nNormal\\nNormal\\nNormal\\nHigh\\nNormal\\nNormal\\nNormal\\nHigh\\nNormal\\nHigh\\n\\nWeak\\nStrong\\nWeak\\nWeak\\nWeak\\nStrong\\nStrong\\nWeak\\nWeak\\nWeak\\nStrong\\nStrong\\nWeak\\nStrong\\n\\nNo\\nNo\\nYes\\nYes\\nYes\\nNo\\nYes\\nNo\\nYes\\nYes\\nYes\\nYes\\nYes\\nNo\\n\\n\\x0cWeather Data Counts\\n\\n\\x0cWeather Data Set\\nDay\\n\\nOutlook\\n\\nTemp\\n\\nHumidity\\n\\nWind\\n\\nPlayTennis\\n\\nD1\\nD2\\nD3\\nD4\\nD5\\nD6\\nD7\\nD8\\nD9\\nD10\\nD11\\nD12\\nD13\\nD14\\n\\nSunny\\nSunny\\nOvercast\\nRain\\nRain\\nRain\\nOvercast\\nSunny\\nSunny\\nRain\\nSunny\\nOvercast\\nOvercast\\nRain\\n\\nHot\\nHot\\nHot\\nMild\\nCool\\nCool\\nCool\\nMild\\nCool\\nMild\\nMild\\nMild\\nHot\\nMild\\n\\nHigh\\nHigh\\nHigh\\nHigh\\nNormal\\nNormal\\nNormal\\nHigh\\nNormal\\nNormal\\nNormal\\nHigh\\nNormal\\nHigh\\n\\nWeak\\nStrong\\nWeak\\nWeak\\nWeak\\nStrong\\nStrong\\nWeak\\nWeak\\nWeak\\nStrong\\nStrong\\nWeak\\nStrong\\n\\nNo\\nNo\\nYes\\nYes\\nYes\\nNo\\nYes\\nNo\\nYes\\nYes\\nYes\\nYes\\nYes\\nNo\\n\\n\\x0cWeather Data Counts\\n\\n\\x0cWeather Data Counts\\n\\n\\x0cA new day to be classified\\nOutlook\\n\\nTemp\\n\\nHumidity\\n\\nWindy\\n\\nPlay\\n\\nSunny\\n\\nCool\\n\\nHigh\\n\\nTrue\\n\\n?\\n\\n\\x0cWe can use the Table as a Model\\n\\n\\x0cOutlook\\n\\nTemp\\n\\nHumidity\\n\\nWindy\\n\\nPlay\\n\\nSunny\\n\\nCool\\n\\nHigh\\n\\nTrue\\n\\n?\\n\\n\\x0cOutlook\\nSunny\\n\\nTemp\\nCool\\n\\nHumidity\\nHigh\\n\\nWindy\\nTrue\\n\\nPlay\\n?\\n\\nLikelihood for the class play tennis equals to Yes\\nYes = 2/9 x 3/9 x 3/9 x 3/9 x 9/14 = 0.0053\\n\\nFor\\nClass=Yes\\n\\n\\x0cLikelihood of the New Day Outcome\\nOutlook\\n\\nTemp\\n\\nHumidity\\n\\nWindy\\n\\nPlay\\n\\nSunny\\n\\nCool\\n\\nHigh\\n\\nTrue\\n\\n?\\n\\nLikelihood of the two classes attribute Play can take\\nFor each Class value (Yes and No)\\nYes = 2/9 x 3/9 x 3/9 x3/9 x 9/14 = 0.0053\\n\\nNo = 3/5 x 1/5 x 4/5 x 3/5 x5/14 = 0.0206\\n\\nWhich class\\nvalue is more\\nlikely?\\n\\n\\x0cLikelihood of the New Day Outcome\\nConvert into probabilities by normalization:\\nProb (Class = Yes) = 0.0053/(0.0053 + 0.0206)= 0.205\\nProb (Class = No) = 0.0206 / (0.0053 + 0.0206) = 0.795\\n\\nProbability for NOT\\nPlay tennis is ~80%\\n\\n\\x0cNa\\xefve Bayes\\u2019s Rule\\n\\nPr[H|E]=\\n\\n\\U0001d477\\U0001d493 \\U0001d46c \\U0001d46f \\U0001d477\\U0001d493[\\U0001d46f]\\n\\U0001d477\\U0001d493[\\U0001d46c]\\n\\n\\x0cNa\\xefve Bayes\\u2019s rule\\nPr[H|E]=\\n\\nA priori probability of H\\n\\n\\U0001d477\\U0001d493 \\U0001d46c \\U0001d46f \\U0001d477\\U0001d493[\\U0001d46f]\\n\\U0001d477\\U0001d493[\\U0001d46c]\\n\\nProbability of event before evidence has been seen\\nPr [H]\\n\\nA posteriori probability of H\\nProbability of event after evidence has been seen\\nPr [H|E]\\n\\n\\x0cNa\\xefve Bayes for Classification\\nWhat\\u2019s the probability of the class given an instance?\\nEvidence E = instance\\n\\nEvent H = class value for instance\\n\\nNa\\xefve Bayes assumption: evidence can be split into\\nindependent parts\\n\\n\\x0cEvidence:\\n\\nOutlook\\n\\nTemp\\n\\nHumidity\\n\\nWindy\\n\\nPlay\\n\\nSunny\\n\\nCool\\n\\nHigh\\n\\nTrue\\n\\n?\\n\\nPr[yes|E]=\\nPr[Outlook=Sunny|yes] x Pr[Temp=Cool|yes] x\\nPr[Humidity=High|yes] x Pr[Windy=True|yes] x Pr[yes]\\n\\nPr[E]\\n\\nProbabilities for class YES =\\n\\n\\U0001d7d0 \\U0001d7d1 \\U0001d7d1 \\U0001d7d1 \\U0001d7d7\\n\\u2217 \\u2217 \\u2217 \\u2217\\n\\U0001d7d7 \\U0001d7d7 \\U0001d7d7 \\U0001d7d7 \\U0001d7cf\\U0001d7d2\\n\\n\\U0001d477\\U0001d493[\\U0001d46c]\\n\\n\\x0cNa\\xefve Bayes Summary\\nNa\\xefve Bayes works amazingly well\\n\\u2022 Violated independence assumption\\n\\nBecause much of classification doesn\\u2019t require accurate\\nprobability estimates as long as maximum probability is\\nassigned to correct class\\nProblem: Adding too many redundant attributes\\n\\u2022 Example: identical attributes\\n\\n\\x0c',\n",
       "  u'uploadDate': datetime.datetime(2016, 4, 1, 20, 24, 8, 769000),\n",
       "  u'username': u'Rikard'},\n",
       " {u'_id': ObjectId('5702b8e5b14376090e8dbec4'),\n",
       "  u'chunkSize': 261120,\n",
       "  u'filename': u'scansmpl.pdf',\n",
       "  u'length': 21530,\n",
       "  u'md5': u'8d2fc6d280b1385302910fd5162eaad2',\n",
       "  u'tags': [u'default'],\n",
       "  u'text': u\"No.\\n\\nTHE SLEREXE COMPANY LIMITED\\n\\nSAPORS LANE - BOOLE - DORSET - BHZS HER\\nI'ELEPHUNI not: (9513) 51617 - \\u010f\\u0179\\x82ux 123456\\n\\nOur Ref. 350/PJC/EAC 18th January, 1972.\\n\\nDr. KN. Cundall,\\nMining Surveys Ltd.,\\nHolroyd Road,\\nReading,\\n\\nBerks.\\n\\nDeer Pete,\\n\\nPermit me to introduce you to the facility of facsimile\\ntransmission.\\n\\nIn facsimile a photocell is caused to perform a raster scan over\\nthe subject copy. The variations of print density on the document\\ncause the photocell to generate an analogous electrical video signal.\\nThis signal is used to modulate a carrier, which is transmitted to a\\nremote destination over a radio or cable communications link.\\n\\nAt the remote terminal, demodulation reconstructs the video\\nsignal, which is used to modulate the density of print produced by a\\nprinting device. This device is scanning in a raster scan synchronised\\nwith that at the transmitting terminal. As a result, a facsimile\\ncopy of the subject document is produced.\\n\\nProbably you have uses for this facility in your organisation.\\n\\nYours sincerely,\\n\\nW.\\nP.J. CROSS\\nGroup Leader - Facsimile Research\\n\\nRegistered in Bun Nu. noes\\nnqimnd om\\xe2\\x80\\x9d: so vmr. Lune, [Her-l. mun.\\n\\n \\n\\n\",\n",
       "  u'uploadDate': datetime.datetime(2016, 4, 4, 18, 56, 37, 463000),\n",
       "  u'username': u'dvader'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(db.fs.files.find())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search database for a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you want to get your hands on all documents with a specific filename. Just do a standard find() on the MongoDB, the do whatever you want with the documents (here I print the upload date)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 documents\n",
      "2016-04-01 12:20:51.911000\n",
      "2016-04-01 12:53:47.650000\n",
      "2016-04-04 18:56:37.463000\n"
     ]
    }
   ],
   "source": [
    "cursor = fs.find({\"filename\" : \"scansmpl.pdf\"}).limit(3)\n",
    "print \"Found\", cursor.count(), \"documents\"\n",
    "for doc in cursor:\n",
    "    print doc.uploadDate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to grab the file using the \"_id\" you must convert it to an ObjectId first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectId('56fe67a3b143762514358154')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bson.objectid import ObjectId\n",
    "fs.find_one({'_id': ObjectId('56fe67a3b143762514358154')})._id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are only interested in the last version you could retrieve it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-04-04 18:56:37.463000\n"
     ]
    }
   ],
   "source": [
    "print fs.get_last_version(\"scansmpl.pdf\").uploadDate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of extracting the text from the scanned pdf earlier was to enable searching for matching substrings to retrieve documents. To do this we need to create an index of the text field. \n",
    "\n",
    "I have yet to figure out how to do this with pymongo, but in the mongo shell this is just one short line (see comment below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#db.fs.files.createIndex({ \"text\": \"text\" } ) # need to implement this in pymongo, works in mongo shell\n",
    "founddocs = fs.find({\"$text\": { \"$search\": \"Cundall\" }})\n",
    "print founddocs.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the found documents to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,doc in enumerate(founddocs):\n",
    "    with open(doc.filename+'_'+str(i), 'w') as f:\n",
    "      f.write(fs.get(doc._id).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now have the original file(s) matching the search terms with a counter suffix in the local folder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
